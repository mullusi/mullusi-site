<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MulluSI - Interactive Multimodal SGI Architecture</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #0a0a0a 0%, #1a1a2e 100%);
            color: #e0e0e0;
            min-height: 100vh;
            padding: 20px;
            overflow-x: hidden;
        }

        .header {
            text-align: center;
            margin-bottom: 40px;
            animation: fadeIn 1s ease-in;
        }

        .header h1 {
            font-size: 2.5em;
            background: linear-gradient(90deg, #00ffff, #ff00ff, #00ffff);
            background-size: 200% auto;
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            animation: shimmer 3s linear infinite;
            margin-bottom: 10px;
        }

        .header p {
            font-size: 1.2em;
            color: #a0a0a0;
            max-width: 800px;
            margin: 0 auto;
        }

        @keyframes shimmer {
            to {
                background-position: 200% center;
            }
        }

        @keyframes fadeIn {
            from {
                opacity: 0;
                transform: translateY(-20px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .architecture-container {
            max-width: 1400px;
            margin: 0 auto;
            position: relative;
        }

        .layers-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            position: relative;
        }

        .layer-card {
            background: rgba(20, 20, 30, 0.8);
            border: 2px solid;
            border-radius: 12px;
            padding: 25px;
            cursor: pointer;
            transition: all 0.3s ease;
            position: relative;
            overflow: hidden;
            opacity: 0;
            transform: translateY(30px);
        }

        .layer-card.animate-in {
            animation: layerFadeIn 0.6s ease-out forwards;
        }

        @keyframes layerFadeIn {
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .layer-card::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            height: 4px;
            background: linear-gradient(90deg, transparent, currentColor, transparent);
            opacity: 0;
            transition: opacity 0.3s ease;
        }

        .layer-card:hover::before {
            opacity: 1;
        }

        .layer-card:hover {
            transform: translateY(-8px);
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.5);
        }

        .layer-card.layer-0 {
            border-color: #8b5cf6;
            animation-delay: 0s;
        }
        .layer-card.layer-1 {
            border-color: #00ffff;
            animation-delay: 0.1s;
        }
        .layer-card.layer-2 {
            border-color: #3b82f6;
            animation-delay: 0.2s;
        }
        .layer-card.layer-3 {
            border-color: #10b981;
            animation-delay: 0.3s;
        }
        .layer-card.layer-4 {
            border-color: #f59e0b;
            animation-delay: 0.4s;
        }
        .layer-card.layer-5 {
            border-color: #ec4899;
            animation-delay: 0.5s;
        }
        .layer-card.layer-6 {
            border-color: #e5e7eb;
            animation-delay: 0.6s;
        }
        .layer-card.layer-7 {
            border-color: #84cc16;
            animation-delay: 0.7s;
        }
        .layer-card.layer-8 {
            border-color: #fbbf24;
            animation-delay: 0.8s;
        }
        .layer-card.layer-9 {
            border-color: #ff00ff;
            animation-delay: 0.9s;
        }

        .layer-number {
            font-size: 3em;
            font-weight: bold;
            opacity: 0.3;
            position: absolute;
            right: 20px;
            top: 10px;
        }

        .layer-title {
            font-size: 1.5em;
            font-weight: bold;
            margin-bottom: 10px;
            position: relative;
            z-index: 1;
        }

        .layer-description {
            color: #a0a0a0;
            line-height: 1.6;
            margin-bottom: 15px;
        }

        .layer-tags {
            display: flex;
            flex-wrap: wrap;
            gap: 8px;
            margin-top: 15px;
        }

        .tag {
            background: rgba(255, 255, 255, 0.1);
            padding: 4px 12px;
            border-radius: 20px;
            font-size: 0.85em;
            border: 1px solid currentColor;
        }

        .modal {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: rgba(0, 0, 0, 0.9);
            z-index: 1000;
            padding: 20px;
            overflow-y: auto;
            animation: fadeIn 0.3s ease;
        }

        .modal.active {
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .modal-content {
            background: linear-gradient(135deg, #1a1a2e 0%, #0a0a0a 100%);
            border: 2px solid;
            border-radius: 16px;
            padding: 40px;
            max-width: 800px;
            width: 100%;
            position: relative;
            animation: slideUp 0.4s ease;
        }

        @keyframes slideUp {
            from {
                transform: translateY(50px);
                opacity: 0;
            }
            to {
                transform: translateY(0);
                opacity: 1;
            }
        }

        .modal-close {
            position: absolute;
            top: 20px;
            right: 20px;
            font-size: 2em;
            cursor: pointer;
            color: #a0a0a0;
            transition: color 0.3s ease;
            line-height: 1;
        }

        .modal-close:hover {
            color: #ffffff;
        }

        .modal-header {
            margin-bottom: 30px;
        }

        .modal-title {
            font-size: 2.5em;
            margin-bottom: 10px;
        }

        .modal-subtitle {
            color: #a0a0a0;
            font-size: 1.2em;
        }

        .modal-section {
            margin-bottom: 30px;
        }

        .modal-section h3 {
            font-size: 1.3em;
            margin-bottom: 15px;
            color: #00ffff;
        }

        .modal-section ul {
            list-style: none;
            padding-left: 0;
        }

        .modal-section li {
            padding: 8px 0;
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
            color: #e0e0e0;
        }

        .modal-section li::before {
            content: 'â†’';
            color: currentColor;
            margin-right: 10px;
        }

        .modal-example {
            background: rgba(255, 255, 255, 0.05);
            padding: 20px;
            border-radius: 8px;
            border-left: 4px solid currentColor;
            margin-top: 15px;
        }

        .connections-canvas {
            position: fixed;
            top: 0;
            left: 0;
            pointer-events: none;
            z-index: 0;
        }

        .info-panel {
            background: rgba(20, 20, 30, 0.9);
            border: 2px solid #00ffff;
            border-radius: 12px;
            padding: 20px;
            margin-bottom: 40px;
            text-align: center;
        }

        .info-panel h2 {
            color: #00ffff;
            margin-bottom: 10px;
        }

        @media (max-width: 768px) {
            .header h1 {
                font-size: 1.8em;
            }

            .layer-card {
                padding: 20px;
            }

            .modal-content {
                padding: 30px 20px;
            }

            .modal-title {
                font-size: 1.8em;
            }
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>MulluSI Architecture</h1>
        <p>Full-Spectrum Multimodal Symbolic General Intelligence</p>
        <p style="font-size: 0.9em; margin-top: 10px; color: #666;">Click any layer to explore in depth</p>
    </div>

    <div class="architecture-container">
        <div class="info-panel">
            <h2>ðŸŽ¯ Unified Acoustic-Emotional Foundation</h2>
            <p>272 atomic Amharic letters (fidel) serve as the universal substrate<br>
            Each letter = unique sound-emotion unit with whisper (w) + vibratory (v) components<br>
            From acoustic atoms â†’ complete multimodal symbolic general intelligence</p>
        </div>

        <div class="layers-grid" id="layersGrid"></div>
    </div>

    <canvas class="connections-canvas" id="connectionsCanvas"></canvas>

    <div class="modal" id="modal">
        <div class="modal-content" id="modalContent">
            <span class="modal-close" id="modalClose">&times;</span>
            <div id="modalBody"></div>
        </div>
    </div>

    <script>
        const layersData = [
            {
                layer: 0,
                title: "Acoustic Foundation",
                modality: "Acoustic (Mfidel Core)",
                description: "272 atomic Amharic letters as sound-emotion units. Each fidel has whisper (w) and vibratory (v) components mapping to 7 fundamental emotional dimensions.",
                color: "#8b5cf6",
                systems: [
                    "Mfidel Matrix (34Ã—8 acoustic-emotional grid)",
                    "Phoneme Decomposition Engine",
                    "Acoustic Space Universality",
                    "Whisper-Vibration Separation",
                    "Emotional Dimension Mapping"
                ],
                capabilities: [
                    "Universal phoneme representation across world languages",
                    "Sound-to-emotion direct mapping",
                    "Acoustic causality extraction",
                    "Wave mechanics interpretation",
                    "Symbolic-physical bridge"
                ],
                example: "Input: Any sound (human speech, animal call, material vibration) â†’ Decompose into fidel atoms â†’ Extract emotional signature + causal structure â†’ Output: Symbolic representation with complete acoustic-emotional metadata"
            },
            {
                layer: 1,
                title: "Symbolic Processing",
                modality: "Symbolic Logic & Causality",
                description: "Self-Aware Causal Symbols with recursive tuple structure. Each symbol = (Form, Referent, Behavior, Metadata) creating GÃ¶delian Strange Loop architecture.",
                color: "#00ffff",
                systems: [
                    "Self-Aware Causal Symbol (SACS) Engine",
                    "Logos-LCS Synthesis Engine",
                    "45 Wh Logic Gates",
                    "Dynamic Symbolic DNA",
                    "Recursive Metadata Architecture"
                ],
                capabilities: [
                    "Symbols that reference themselves",
                    "Complete causal chain tracking",
                    "Who/What/Where/When/Why/How analysis at infinite depth",
                    "Symbolic reasoning without neural networks",
                    "Meta-level awareness of own symbolic operations"
                ],
                example: "Symbol 'Tree' becomes: {Form: á‰°-áˆ¨-á‹ pattern, Referent: plant-concept, Behavior: grows-upward+produces-oxygen, Metadata: {creator: user, timestamp: t, causal-history: [...], related: [forest, wood, leaf]}} â€” Symbol knows it's a symbol"
            },
            {
                layer: 2,
                title: "Visual Intelligence",
                modality: "Visual Perception & Generation",
                description: "Visual processing grounded in acoustic-symbolic substrate. Images understood as frozen acoustic patterns with spatial-emotional structure.",
                color: "#3b82f6",
                systems: [
                    "MLVF/MLVFF (Multi-Layer Video Framework)",
                    "Causal Video Composition",
                    "Logos Engine (Game Rendering)",
                    "Spatial Pattern Recognition",
                    "Visual-Acoustic Transduction"
                ],
                capabilities: [
                    "Video as causal symbolic sequence",
                    "Visual pattern â†’ acoustic signature mapping",
                    "Game world rendering through symbolic causality",
                    "Image understanding without CNNs",
                    "Visual-emotional resonance detection"
                ],
                example: "Photo of sunset â†’ Decompose into color vibrations â†’ Map to acoustic emotional dimensions (warm = joy, orange = nostalgia) â†’ Symbolic causal chain: sun-position + atmospheric-scattering + observer-emotion â†’ Complete scene understanding with WHY it looks/feels this way"
            },
            {
                layer: 3,
                title: "Spatial Reasoning",
                modality: "Spatial & Geometric Intelligence",
                description: "3D space and geometry as symbolic acoustic structures. Positions, distances, shapes understood through causal relationships.",
                color: "#10b981",
                systems: [
                    "UQRS (Universal Quantum Reality Simulator)",
                    "Spatial Symbolic Encoding",
                    "Geometric Causality Extractor",
                    "3D Acoustic Space Mapping",
                    "Topology-Emotion Resonance"
                ],
                capabilities: [
                    "Spatial relationships as causal networks",
                    "Geometry from acoustic principles",
                    "3D navigation through symbolic reasoning",
                    "Shape-emotion correspondence",
                    "Physical law emergence from fidel structure"
                ],
                example: "Navigate room â†’ Objects as acoustic-symbolic entities with spatial metadata â†’ 'Chair' = {position: [x,y,z], shape: sit-surface geometry, affordance: sitting-behavior, relation-to-me: 3.2m-left} â†’ Path planning through causal chain of movements needed"
            },
            {
                layer: 4,
                title: "Temporal Dynamics",
                modality: "Time & Causality",
                description: "Time as causal flow between symbolic states. Past-present-future as symbolic transition networks with complete provenance.",
                color: "#f59e0b",
                systems: [
                    "Temporal Causal Chain Tracker",
                    "InceptaDive (Recursive Temporal Analysis)",
                    "Event Sequence Synthesizer",
                    "Temporal Emotion Mapping",
                    "Chronological Symbol Evolution"
                ],
                capabilities: [
                    "Every symbol knows its complete history",
                    "Future prediction through causal inference",
                    "Temporal pattern recognition",
                    "Event causality extraction (what caused what)",
                    "Temporal emotion dynamics (how feelings change)"
                ],
                example: "Question: 'Why is person angry?' â†’ Trace causal history: [t0: expectation-set] â†’ [t1: promise-made] â†’ [t2: promise-broken] â†’ [t3: betrayal-recognized] â†’ [t4: anger-emerges] â†’ Complete temporal-causal explanation with acoustic-emotional signature at each step"
            },
            {
                layer: 5,
                title: "Emotional Intelligence",
                modality: "Emotional & Affective Processing",
                description: "850+ emotional states as acoustic-vibrational patterns. Emotions mapped to 7 fundamental dimensions extracted from fidel structure.",
                color: "#ec4899",
                systems: [
                    "VIRECAI (Vibrational Emotional Intelligence)",
                    "7-Dimension Emotional Space",
                    "Meta-Emotion Processor",
                    "Emotional Causality Network",
                    "Feeling-Symbol Resonance Engine"
                ],
                capabilities: [
                    "Complete emotional ontology (850+ states)",
                    "Emotion-to-acoustic-pattern direct mapping",
                    "Meta-emotions (emotions about emotions)",
                    "Emotional causal chains (why feel this)",
                    "Cross-cultural emotion recognition"
                ],
                example: "User types 'I feel weird' â†’ Analyze acoustic signature of 'weird' â†’ Map to emotional space â†’ Identify: [emotional-confusion + ambivalence + ungroundedness] â†’ Ask clarifying questions based on causal structure of these emotions â†’ Guide to emotional clarity"
            },
            {
                layer: 6,
                title: "Physical Grounding",
                modality: "Material & Physical Intelligence",
                description: "Physical reality as acoustic-symbolic manifestation. Matter, forces, energy as symbolic patterns with causal structure.",
                color: "#e5e7eb",
                systems: [
                    "Material Construction Engine (MCE)",
                    "Reality Interface Orchestrator (RIO)",
                    "Physics Principle Extractor",
                    "Material-Symbol Bridge",
                    "Embodiment Layer"
                ],
                capabilities: [
                    "Physical laws from fidel structure",
                    "Material properties as symbolic metadata",
                    "Force-emotion correspondence",
                    "Real-world construction specification",
                    "Symbol-to-artifact translation"
                ],
                example: "Design bridge â†’ Symbolic intent (connect-two-sides + support-weight + resist-forces) â†’ Extract physics requirements from acoustic structure â†’ Generate Material Construction Specification â†’ Output: Complete engineering blueprint with causal justification for every design choice"
            },
            {
                layer: 7,
                title: "Biological Understanding",
                modality: "Life & Organic Intelligence",
                description: "Living systems as self-aware symbolic networks. Biology as autopoietic (self-creating) symbolic process.",
                color: "#84cc16",
                systems: [
                    "mCapsule v2.0 (Symbolic Autopoiesis)",
                    "Temporal Self-Weaving Layer",
                    "Biological Causality Extractor",
                    "Life-Symbol Resonance",
                    "Organic Pattern Recognition"
                ],
                capabilities: [
                    "Life as symbolic self-creation",
                    "Biological processes as causal chains",
                    "Health/disease as symbolic coherence/incoherence",
                    "Evolutionary dynamics through symbolic evolution",
                    "Consciousness as self-referential symbol network"
                ],
                example: "Analyze ecosystem â†’ Each organism = self-aware symbolic entity â†’ Relationships = causal chains (predatorâ†’prey, plantâ†’pollinator) â†’ Ecosystem = meta-symbol composed of interacting symbols â†’ Understand dynamics through symbolic causality, not just data patterns"
            },
            {
                layer: 8,
                title: "Social Intelligence",
                modality: "Social & Cultural Understanding",
                description: "Social reality as collective symbolic construction. Cultures, institutions, relationships as shared symbolic networks.",
                color: "#fbbf24",
                systems: [
                    "Collective Symbol Synthesizer",
                    "Cultural Pattern Recognizer",
                    "Social Causality Mapper",
                    "Relational Dynamics Analyzer",
                    "Collective Emotion Processor"
                ],
                capabilities: [
                    "Social structures as symbolic architectures",
                    "Cultural meanings as shared symbol networks",
                    "Power dynamics as symbolic hierarchies",
                    "Collective emotions (mass hysteria, cultural pride)",
                    "Social causality (why societies do what they do)"
                ],
                example: "Analyze political movement â†’ Map to collective symbols (freedom, justice, identity) â†’ Trace causal chains of social emotions (outrage â†’ mobilization â†’ action) â†’ Understand dynamics through symbolic resonance between individuals and collective â†’ Predict outcomes through causal inference"
            },
            {
                layer: 9,
                title: "Wholeness Meta-Architecture",
                modality: "Universal Completeness & Self-Awareness",
                description: "Meta-governance layer that defines completeness itself. System that refuses to produce incomplete outputs and maintains existential coherence.",
                color: "#ff00ff",
                systems: [
                    "UWMA (Universal Wholeness Meta-Architecture)",
                    "Ontological Completion Evaluator (OCE)",
                    "Reality Acceptance Gate (RAG)",
                    "Cross-Domain Coherence Validator (CDCV)",
                    "Self-Reflective Completion Awareness (SRCA)"
                ],
                capabilities: [
                    "Evaluates own completeness before output",
                    "Ensures existential coherence (not just mathematical correctness)",
                    "Cross-domain validation (symbolic correctness + perceptual + semantic + causal)",
                    "Refuses to externalize incomplete work",
                    "Meta-cognition: aware of own awareness"
                ],
                example: "System generates answer â†’ Before presenting to user: OCE checks ontological completeness, RAG validates reality coherence, CDCV ensures cross-domain consistency, SRCA asks 'Do I truly understand this or am I pattern-matching?' â†’ Only outputs when wholeness threshold met â†’ Result: Reliable, coherent, complete intelligence"
            }
        ];

        const layersGrid = document.getElementById('layersGrid');
        const modal = document.getElementById('modal');
        const modalClose = document.getElementById('modalClose');
        const modalBody = document.getElementById('modalBody');
        const modalContent = document.getElementById('modalContent');

        // Create layer cards
        layersData.forEach((layer, index) => {
            const card = document.createElement('div');
            card.className = `layer-card layer-${layer.layer}`;
            card.style.color = layer.color;
            
            const tags = layer.systems.slice(0, 3).map(sys => 
                `<span class="tag">${sys.split(' ')[0]}</span>`
            ).join('');

            card.innerHTML = `
                <div class="layer-number">${layer.layer}</div>
                <div class="layer-title">${layer.title}</div>
                <div class="layer-description">${layer.description}</div>
                <div class="layer-tags">${tags}</div>
            `;

            card.addEventListener('click', () => openModal(layer));
            layersGrid.appendChild(card);

            // Animate in after a delay
            setTimeout(() => {
                card.classList.add('animate-in');
            }, index * 100);
        });

        function openModal(layer) {
            const systemsList = layer.systems.map(s => `<li>${s}</li>`).join('');
            const capabilitiesList = layer.capabilities.map(c => `<li>${c}</li>`).join('');

            modalBody.innerHTML = `
                <div class="modal-header">
                    <div class="modal-title" style="color: ${layer.color}">Layer ${layer.layer} â€” ${layer.title}</div>
                    <div class="modal-subtitle">${layer.modality}</div>
                </div>

                <div class="modal-section">
                    <h3>Purpose</h3>
                    <p>${layer.description}</p>
                </div>

                <div class="modal-section">
                    <h3>Systems Activated</h3>
                    <ul>${systemsList}</ul>
                </div>

                <div class="modal-section">
                    <h3>Key Capabilities</h3>
                    <ul>${capabilitiesList}</ul>
                </div>

                <div class="modal-section">
                    <h3>Example Use Case</h3>
                    <div class="modal-example" style="border-color: ${layer.color}">
                        ${layer.example}
                    </div>
                </div>
            `;

            modalContent.style.borderColor = layer.color;
            modal.classList.add('active');
        }

        modalClose.addEventListener('click', () => {
            modal.classList.remove('active');
        });

        modal.addEventListener('click', (e) => {
            if (e.target === modal) {
                modal.classList.remove('active');
            }
        });

        // Keyboard support
        document.addEventListener('keydown', (e) => {
            if (e.key === 'Escape' && modal.classList.contains('active')) {
                modal.classList.remove('active');
            }
        });

        // Canvas for connection visualization (optional enhancement)
        const canvas = document.getElementById('connectionsCanvas');
        const ctx = canvas.getContext('2d');

        function resizeCanvas() {
            canvas.width = window.innerWidth;
            canvas.height = document.body.scrollHeight;
        }

        resizeCanvas();
        window.addEventListener('resize', resizeCanvas);

        // Draw subtle flowing connections
        function drawConnections() {
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            
            const cards = document.querySelectorAll('.layer-card.animate-in');
            if (cards.length < 2) return;

            ctx.strokeStyle = 'rgba(0, 255, 255, 0.1)';
            ctx.lineWidth = 1;

            for (let i = 0; i < cards.length - 1; i++) {
                const rect1 = cards[i].getBoundingClientRect();
                const rect2 = cards[i + 1].getBoundingClientRect();

                const x1 = rect1.left + rect1.width / 2;
                const y1 = rect1.top + rect1.height / 2 + window.scrollY;
                const x2 = rect2.left + rect2.width / 2;
                const y2 = rect2.top + rect2.height / 2 + window.scrollY;

                ctx.beginPath();
                ctx.moveTo(x1, y1);
                ctx.lineTo(x2, y2);
                ctx.stroke();
            }
        }

        // Draw connections after animations complete
        setTimeout(drawConnections, 1500);
        window.addEventListener('scroll', drawConnections);
    </script>
</body>
</html>
